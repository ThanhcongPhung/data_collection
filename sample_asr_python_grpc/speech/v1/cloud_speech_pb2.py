# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: cloud_speech.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='cloud_speech.proto',
  package='vais.cloud.speech.v1',
  syntax='proto3',
  serialized_options=_b('\n\027vn.vais.cloud.speech.v1B\013SpeechProtoP\001\370\001\001'),
  serialized_pb=_b('\n\x12\x63loud_speech.proto\x12\x14vais.cloud.speech.v1\"6\n\x16IntentRecognizeRequest\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x0e\n\x06\x61pp_id\x18\x02 \x01(\t\"\xd7\x01\n StreamingIntentRecognizeResponse\x12\x44\n\rintent_result\x18\x01 \x01(\x0b\x32+.vais.cloud.speech.v1.IntentRecognizeResultH\x00\x12H\n\x0c\x61sr_response\x18\x02 \x01(\x0b\x32\x30.vais.cloud.speech.v1.StreamingRecognizeResponseH\x00\x12\x10\n\x08is_final\x18\x03 \x01(\x08\x42\x11\n\x0fintent_response\"\xaa\x01\n\x15IntentRecognizeResult\x12\x12\n\ntranscript\x18\x01 \x01(\t\x12\x0e\n\x06intent\x18\x02 \x01(\t\x12\x12\n\nparameters\x18\x03 \x01(\t\x12\x15\n\rtext_response\x18\x04 \x01(\t\x12\x16\n\x0e\x61udio_response\x18\x05 \x01(\t\x12\x16\n\x0eneed_more_info\x18\x06 \x01(\x08\x12\x12\n\nconfidence\x18\x07 \x01(\x02\"K\n\nTtsRequest\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\r\n\x05voice\x18\x02 \x01(\t\x12\r\n\x05speed\x18\x03 \x01(\x02\x12\x11\n\thalf_tone\x18\x04 \x01(\x02\"\x1c\n\x0bTtsResponse\x12\r\n\x05\x61udio\x18\x01 \x01(\t\"\x82\x01\n\x10RecognizeRequest\x12\x37\n\x06\x63onfig\x18\x01 \x01(\x0b\x32\'.vais.cloud.speech.v1.RecognitionConfig\x12\x35\n\x05\x61udio\x18\x02 \x01(\x0b\x32&.vais.cloud.speech.v1.RecognitionAudio\"\x97\x01\n\x19StreamingRecognizeRequest\x12L\n\x10streaming_config\x18\x01 \x01(\x0b\x32\x30.vais.cloud.speech.v1.StreamingRecognitionConfigH\x00\x12\x17\n\raudio_content\x18\x02 \x01(\x0cH\x00\x42\x13\n\x11streaming_request\"\x99\x01\n\x1aStreamingRecognitionConfig\x12\x37\n\x06\x63onfig\x18\x01 \x01(\x0b\x32\'.vais.cloud.speech.v1.RecognitionConfig\x12\x18\n\x10single_utterance\x18\x02 \x01(\x08\x12\x17\n\x0finterim_results\x18\x03 \x01(\x08\x12\x0f\n\x07session\x18\x04 \x01(\t\"\xe7\x03\n\x11RecognitionConfig\x12G\n\x08\x65ncoding\x18\x01 \x01(\x0e\x32\x35.vais.cloud.speech.v1.RecognitionConfig.AudioEncoding\x12\x19\n\x11sample_rate_hertz\x18\x02 \x01(\x05\x12\x15\n\rlanguage_code\x18\x03 \x01(\t\x12\x18\n\x10max_alternatives\x18\x04 \x01(\x05\x12\x18\n\x10profanity_filter\x18\x05 \x01(\x08\x12<\n\x0fspeech_contexts\x18\x06 \x03(\x0b\x32#.vais.cloud.speech.v1.SpeechContext\x12 \n\x18\x65nable_word_time_offsets\x18\x08 \x01(\x08\x12\x35\n\x0bmodel_param\x18\t \x01(\x0b\x32 .vais.cloud.speech.v1.ModelParam\"\x8b\x01\n\rAudioEncoding\x12\x18\n\x14\x45NCODING_UNSPECIFIED\x10\x00\x12\x0c\n\x08LINEAR16\x10\x01\x12\x08\n\x04\x46LAC\x10\x02\x12\t\n\x05MULAW\x10\x03\x12\x07\n\x03\x41MR\x10\x04\x12\n\n\x06\x41MR_WB\x10\x05\x12\x0c\n\x08OGG_OPUS\x10\x06\x12\x1a\n\x16SPEEX_WITH_HEADER_BYTE\x10\x07\"\'\n\nModelParam\x12\n\n\x02\x61m\x18\x01 \x01(\t\x12\r\n\x05graph\x18\x02 \x01(\t\"0\n\rSpeechContext\x12\x0f\n\x07phrases\x18\x01 \x03(\t\x12\x0e\n\x06\x61pp_id\x18\x02 \x01(\t\"D\n\x10RecognitionAudio\x12\x11\n\x07\x63ontent\x18\x01 \x01(\x0cH\x00\x12\r\n\x03uri\x18\x02 \x01(\tH\x00\x42\x0e\n\x0c\x61udio_source\"S\n\x11RecognizeResponse\x12>\n\x07results\x18\x02 \x03(\x0b\x32-.vais.cloud.speech.v1.SpeechRecognitionResult\"\x8a\x02\n\x1aStreamingRecognizeResponse\x12\x41\n\x07results\x18\x02 \x03(\x0b\x32\x30.vais.cloud.speech.v1.StreamingRecognitionResult\x12[\n\x11speech_event_type\x18\x04 \x01(\x0e\x32@.vais.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType\"L\n\x0fSpeechEventType\x12\x1c\n\x18SPEECH_EVENT_UNSPECIFIED\x10\x00\x12\x1b\n\x17\x45ND_OF_SINGLE_UTTERANCE\x10\x01\"\xb9\x01\n\x1aStreamingRecognitionResult\x12H\n\x0c\x61lternatives\x18\x01 \x03(\x0b\x32\x32.vais.cloud.speech.v1.SpeechRecognitionAlternative\x12\x10\n\x08is_final\x18\x02 \x01(\x08\x12\x11\n\tstability\x18\x03 \x01(\x02\x12\x16\n\x0e\x61udio_filename\x18\x04 \x01(\t\x12\x14\n\x0c\x61udio_length\x18\x05 \x01(\x02\"c\n\x17SpeechRecognitionResult\x12H\n\x0c\x61lternatives\x18\x01 \x03(\x0b\x32\x32.vais.cloud.speech.v1.SpeechRecognitionAlternative\"u\n\x1cSpeechRecognitionAlternative\x12\x12\n\ntranscript\x18\x01 \x01(\t\x12\x12\n\nconfidence\x18\x02 \x01(\x02\x12-\n\x05words\x18\x03 \x03(\x0b\x32\x1e.vais.cloud.speech.v1.WordInfo\"\x92\x01\n\x08WordInfo\x12\x32\n\nstart_time\x18\x01 \x01(\x0b\x32\x1e.vais.cloud.speech.v1.Duration\x12\x30\n\x08\x65nd_time\x18\x02 \x01(\x0b\x32\x1e.vais.cloud.speech.v1.Duration\x12\x0c\n\x04word\x18\x03 \x01(\t\x12\x12\n\nconfidence\x18\x04 \x01(\x02\"*\n\x08\x44uration\x12\x0f\n\x07seconds\x18\x01 \x01(\x03\x12\r\n\x05nanos\x18\x02 \x01(\x05\x32\xfb\x05\n\x06Speech\x12^\n\tRecognize\x12&.vais.cloud.speech.v1.RecognizeRequest\x1a\'.vais.cloud.speech.v1.RecognizeResponse\"\x00\x12\x89\x01\n\x18StreamingIntentRecognize\x12/.vais.cloud.speech.v1.StreamingRecognizeRequest\x1a\x36.vais.cloud.speech.v1.StreamingIntentRecognizeResponse\"\x00(\x01\x30\x01\x12}\n\x12StreamingRecognize\x12/.vais.cloud.speech.v1.StreamingRecognizeRequest\x1a\x30.vais.cloud.speech.v1.StreamingRecognizeResponse\"\x00(\x01\x30\x01\x12\\\n\x13Text2SpeechHmmAiHoa\x12 .vais.cloud.speech.v1.TtsRequest\x1a!.vais.cloud.speech.v1.TtsResponse\"\x00\x12\x61\n\x18Text2SpeechHmmMinhNguyet\x12 .vais.cloud.speech.v1.TtsRequest\x1a!.vais.cloud.speech.v1.TtsResponse\"\x00\x12_\n\x16Text2SpeechConcatAiHoa\x12 .vais.cloud.speech.v1.TtsRequest\x1a!.vais.cloud.speech.v1.TtsResponse\"\x00\x12\x64\n\x1bText2SpeechConcatMinhNguyet\x12 .vais.cloud.speech.v1.TtsRequest\x1a!.vais.cloud.speech.v1.TtsResponse\"\x00\x42+\n\x17vn.vais.cloud.speech.v1B\x0bSpeechProtoP\x01\xf8\x01\x01\x62\x06proto3')
)



_RECOGNITIONCONFIG_AUDIOENCODING = _descriptor.EnumDescriptor(
  name='AudioEncoding',
  full_name='vais.cloud.speech.v1.RecognitionConfig.AudioEncoding',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='ENCODING_UNSPECIFIED', index=0, number=0,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='LINEAR16', index=1, number=1,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='FLAC', index=2, number=2,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='MULAW', index=3, number=3,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='AMR', index=4, number=4,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='AMR_WB', index=5, number=5,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='OGG_OPUS', index=6, number=6,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='SPEEX_WITH_HEADER_BYTE', index=7, number=7,
      serialized_options=None,
      type=None),
  ],
  containing_type=None,
  serialized_options=None,
  serialized_start=1390,
  serialized_end=1529,
)
_sym_db.RegisterEnumDescriptor(_RECOGNITIONCONFIG_AUDIOENCODING)

_STREAMINGRECOGNIZERESPONSE_SPEECHEVENTTYPE = _descriptor.EnumDescriptor(
  name='SpeechEventType',
  full_name='vais.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='SPEECH_EVENT_UNSPECIFIED', index=0, number=0,
      serialized_options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='END_OF_SINGLE_UTTERANCE', index=1, number=1,
      serialized_options=None,
      type=None),
  ],
  containing_type=None,
  serialized_options=None,
  serialized_start=1968,
  serialized_end=2044,
)
_sym_db.RegisterEnumDescriptor(_STREAMINGRECOGNIZERESPONSE_SPEECHEVENTTYPE)


_INTENTRECOGNIZEREQUEST = _descriptor.Descriptor(
  name='IntentRecognizeRequest',
  full_name='vais.cloud.speech.v1.IntentRecognizeRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='text', full_name='vais.cloud.speech.v1.IntentRecognizeRequest.text', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='app_id', full_name='vais.cloud.speech.v1.IntentRecognizeRequest.app_id', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=44,
  serialized_end=98,
)


_STREAMINGINTENTRECOGNIZERESPONSE = _descriptor.Descriptor(
  name='StreamingIntentRecognizeResponse',
  full_name='vais.cloud.speech.v1.StreamingIntentRecognizeResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='intent_result', full_name='vais.cloud.speech.v1.StreamingIntentRecognizeResponse.intent_result', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='asr_response', full_name='vais.cloud.speech.v1.StreamingIntentRecognizeResponse.asr_response', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='is_final', full_name='vais.cloud.speech.v1.StreamingIntentRecognizeResponse.is_final', index=2,
      number=3, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='intent_response', full_name='vais.cloud.speech.v1.StreamingIntentRecognizeResponse.intent_response',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=101,
  serialized_end=316,
)


_INTENTRECOGNIZERESULT = _descriptor.Descriptor(
  name='IntentRecognizeResult',
  full_name='vais.cloud.speech.v1.IntentRecognizeResult',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='transcript', full_name='vais.cloud.speech.v1.IntentRecognizeResult.transcript', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='intent', full_name='vais.cloud.speech.v1.IntentRecognizeResult.intent', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='parameters', full_name='vais.cloud.speech.v1.IntentRecognizeResult.parameters', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='text_response', full_name='vais.cloud.speech.v1.IntentRecognizeResult.text_response', index=3,
      number=4, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='audio_response', full_name='vais.cloud.speech.v1.IntentRecognizeResult.audio_response', index=4,
      number=5, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='need_more_info', full_name='vais.cloud.speech.v1.IntentRecognizeResult.need_more_info', index=5,
      number=6, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='confidence', full_name='vais.cloud.speech.v1.IntentRecognizeResult.confidence', index=6,
      number=7, type=2, cpp_type=6, label=1,
      has_default_value=False, default_value=float(0),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=319,
  serialized_end=489,
)


_TTSREQUEST = _descriptor.Descriptor(
  name='TtsRequest',
  full_name='vais.cloud.speech.v1.TtsRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='text', full_name='vais.cloud.speech.v1.TtsRequest.text', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='voice', full_name='vais.cloud.speech.v1.TtsRequest.voice', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='speed', full_name='vais.cloud.speech.v1.TtsRequest.speed', index=2,
      number=3, type=2, cpp_type=6, label=1,
      has_default_value=False, default_value=float(0),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='half_tone', full_name='vais.cloud.speech.v1.TtsRequest.half_tone', index=3,
      number=4, type=2, cpp_type=6, label=1,
      has_default_value=False, default_value=float(0),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=491,
  serialized_end=566,
)


_TTSRESPONSE = _descriptor.Descriptor(
  name='TtsResponse',
  full_name='vais.cloud.speech.v1.TtsResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='audio', full_name='vais.cloud.speech.v1.TtsResponse.audio', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=568,
  serialized_end=596,
)


_RECOGNIZEREQUEST = _descriptor.Descriptor(
  name='RecognizeRequest',
  full_name='vais.cloud.speech.v1.RecognizeRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='config', full_name='vais.cloud.speech.v1.RecognizeRequest.config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='audio', full_name='vais.cloud.speech.v1.RecognizeRequest.audio', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=599,
  serialized_end=729,
)


_STREAMINGRECOGNIZEREQUEST = _descriptor.Descriptor(
  name='StreamingRecognizeRequest',
  full_name='vais.cloud.speech.v1.StreamingRecognizeRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='streaming_config', full_name='vais.cloud.speech.v1.StreamingRecognizeRequest.streaming_config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='audio_content', full_name='vais.cloud.speech.v1.StreamingRecognizeRequest.audio_content', index=1,
      number=2, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='streaming_request', full_name='vais.cloud.speech.v1.StreamingRecognizeRequest.streaming_request',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=732,
  serialized_end=883,
)


_STREAMINGRECOGNITIONCONFIG = _descriptor.Descriptor(
  name='StreamingRecognitionConfig',
  full_name='vais.cloud.speech.v1.StreamingRecognitionConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='config', full_name='vais.cloud.speech.v1.StreamingRecognitionConfig.config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='single_utterance', full_name='vais.cloud.speech.v1.StreamingRecognitionConfig.single_utterance', index=1,
      number=2, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='interim_results', full_name='vais.cloud.speech.v1.StreamingRecognitionConfig.interim_results', index=2,
      number=3, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='session', full_name='vais.cloud.speech.v1.StreamingRecognitionConfig.session', index=3,
      number=4, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=886,
  serialized_end=1039,
)


_RECOGNITIONCONFIG = _descriptor.Descriptor(
  name='RecognitionConfig',
  full_name='vais.cloud.speech.v1.RecognitionConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='encoding', full_name='vais.cloud.speech.v1.RecognitionConfig.encoding', index=0,
      number=1, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='sample_rate_hertz', full_name='vais.cloud.speech.v1.RecognitionConfig.sample_rate_hertz', index=1,
      number=2, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='language_code', full_name='vais.cloud.speech.v1.RecognitionConfig.language_code', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='max_alternatives', full_name='vais.cloud.speech.v1.RecognitionConfig.max_alternatives', index=3,
      number=4, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='profanity_filter', full_name='vais.cloud.speech.v1.RecognitionConfig.profanity_filter', index=4,
      number=5, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='speech_contexts', full_name='vais.cloud.speech.v1.RecognitionConfig.speech_contexts', index=5,
      number=6, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='enable_word_time_offsets', full_name='vais.cloud.speech.v1.RecognitionConfig.enable_word_time_offsets', index=6,
      number=8, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='model_param', full_name='vais.cloud.speech.v1.RecognitionConfig.model_param', index=7,
      number=9, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _RECOGNITIONCONFIG_AUDIOENCODING,
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1042,
  serialized_end=1529,
)


_MODELPARAM = _descriptor.Descriptor(
  name='ModelParam',
  full_name='vais.cloud.speech.v1.ModelParam',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='am', full_name='vais.cloud.speech.v1.ModelParam.am', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='graph', full_name='vais.cloud.speech.v1.ModelParam.graph', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1531,
  serialized_end=1570,
)


_SPEECHCONTEXT = _descriptor.Descriptor(
  name='SpeechContext',
  full_name='vais.cloud.speech.v1.SpeechContext',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='phrases', full_name='vais.cloud.speech.v1.SpeechContext.phrases', index=0,
      number=1, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='app_id', full_name='vais.cloud.speech.v1.SpeechContext.app_id', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1572,
  serialized_end=1620,
)


_RECOGNITIONAUDIO = _descriptor.Descriptor(
  name='RecognitionAudio',
  full_name='vais.cloud.speech.v1.RecognitionAudio',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='content', full_name='vais.cloud.speech.v1.RecognitionAudio.content', index=0,
      number=1, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='uri', full_name='vais.cloud.speech.v1.RecognitionAudio.uri', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='audio_source', full_name='vais.cloud.speech.v1.RecognitionAudio.audio_source',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=1622,
  serialized_end=1690,
)


_RECOGNIZERESPONSE = _descriptor.Descriptor(
  name='RecognizeResponse',
  full_name='vais.cloud.speech.v1.RecognizeResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='results', full_name='vais.cloud.speech.v1.RecognizeResponse.results', index=0,
      number=2, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1692,
  serialized_end=1775,
)


_STREAMINGRECOGNIZERESPONSE = _descriptor.Descriptor(
  name='StreamingRecognizeResponse',
  full_name='vais.cloud.speech.v1.StreamingRecognizeResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='results', full_name='vais.cloud.speech.v1.StreamingRecognizeResponse.results', index=0,
      number=2, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='speech_event_type', full_name='vais.cloud.speech.v1.StreamingRecognizeResponse.speech_event_type', index=1,
      number=4, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _STREAMINGRECOGNIZERESPONSE_SPEECHEVENTTYPE,
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1778,
  serialized_end=2044,
)


_STREAMINGRECOGNITIONRESULT = _descriptor.Descriptor(
  name='StreamingRecognitionResult',
  full_name='vais.cloud.speech.v1.StreamingRecognitionResult',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='alternatives', full_name='vais.cloud.speech.v1.StreamingRecognitionResult.alternatives', index=0,
      number=1, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='is_final', full_name='vais.cloud.speech.v1.StreamingRecognitionResult.is_final', index=1,
      number=2, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='stability', full_name='vais.cloud.speech.v1.StreamingRecognitionResult.stability', index=2,
      number=3, type=2, cpp_type=6, label=1,
      has_default_value=False, default_value=float(0),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='audio_filename', full_name='vais.cloud.speech.v1.StreamingRecognitionResult.audio_filename', index=3,
      number=4, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='audio_length', full_name='vais.cloud.speech.v1.StreamingRecognitionResult.audio_length', index=4,
      number=5, type=2, cpp_type=6, label=1,
      has_default_value=False, default_value=float(0),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=2047,
  serialized_end=2232,
)


_SPEECHRECOGNITIONRESULT = _descriptor.Descriptor(
  name='SpeechRecognitionResult',
  full_name='vais.cloud.speech.v1.SpeechRecognitionResult',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='alternatives', full_name='vais.cloud.speech.v1.SpeechRecognitionResult.alternatives', index=0,
      number=1, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=2234,
  serialized_end=2333,
)


_SPEECHRECOGNITIONALTERNATIVE = _descriptor.Descriptor(
  name='SpeechRecognitionAlternative',
  full_name='vais.cloud.speech.v1.SpeechRecognitionAlternative',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='transcript', full_name='vais.cloud.speech.v1.SpeechRecognitionAlternative.transcript', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='confidence', full_name='vais.cloud.speech.v1.SpeechRecognitionAlternative.confidence', index=1,
      number=2, type=2, cpp_type=6, label=1,
      has_default_value=False, default_value=float(0),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='words', full_name='vais.cloud.speech.v1.SpeechRecognitionAlternative.words', index=2,
      number=3, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=2335,
  serialized_end=2452,
)


_WORDINFO = _descriptor.Descriptor(
  name='WordInfo',
  full_name='vais.cloud.speech.v1.WordInfo',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='start_time', full_name='vais.cloud.speech.v1.WordInfo.start_time', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='end_time', full_name='vais.cloud.speech.v1.WordInfo.end_time', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='word', full_name='vais.cloud.speech.v1.WordInfo.word', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='confidence', full_name='vais.cloud.speech.v1.WordInfo.confidence', index=3,
      number=4, type=2, cpp_type=6, label=1,
      has_default_value=False, default_value=float(0),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=2455,
  serialized_end=2601,
)


_DURATION = _descriptor.Descriptor(
  name='Duration',
  full_name='vais.cloud.speech.v1.Duration',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='seconds', full_name='vais.cloud.speech.v1.Duration.seconds', index=0,
      number=1, type=3, cpp_type=2, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='nanos', full_name='vais.cloud.speech.v1.Duration.nanos', index=1,
      number=2, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=2603,
  serialized_end=2645,
)

_STREAMINGINTENTRECOGNIZERESPONSE.fields_by_name['intent_result'].message_type = _INTENTRECOGNIZERESULT
_STREAMINGINTENTRECOGNIZERESPONSE.fields_by_name['asr_response'].message_type = _STREAMINGRECOGNIZERESPONSE
_STREAMINGINTENTRECOGNIZERESPONSE.oneofs_by_name['intent_response'].fields.append(
  _STREAMINGINTENTRECOGNIZERESPONSE.fields_by_name['intent_result'])
_STREAMINGINTENTRECOGNIZERESPONSE.fields_by_name['intent_result'].containing_oneof = _STREAMINGINTENTRECOGNIZERESPONSE.oneofs_by_name['intent_response']
_STREAMINGINTENTRECOGNIZERESPONSE.oneofs_by_name['intent_response'].fields.append(
  _STREAMINGINTENTRECOGNIZERESPONSE.fields_by_name['asr_response'])
_STREAMINGINTENTRECOGNIZERESPONSE.fields_by_name['asr_response'].containing_oneof = _STREAMINGINTENTRECOGNIZERESPONSE.oneofs_by_name['intent_response']
_RECOGNIZEREQUEST.fields_by_name['config'].message_type = _RECOGNITIONCONFIG
_RECOGNIZEREQUEST.fields_by_name['audio'].message_type = _RECOGNITIONAUDIO
_STREAMINGRECOGNIZEREQUEST.fields_by_name['streaming_config'].message_type = _STREAMINGRECOGNITIONCONFIG
_STREAMINGRECOGNIZEREQUEST.oneofs_by_name['streaming_request'].fields.append(
  _STREAMINGRECOGNIZEREQUEST.fields_by_name['streaming_config'])
_STREAMINGRECOGNIZEREQUEST.fields_by_name['streaming_config'].containing_oneof = _STREAMINGRECOGNIZEREQUEST.oneofs_by_name['streaming_request']
_STREAMINGRECOGNIZEREQUEST.oneofs_by_name['streaming_request'].fields.append(
  _STREAMINGRECOGNIZEREQUEST.fields_by_name['audio_content'])
_STREAMINGRECOGNIZEREQUEST.fields_by_name['audio_content'].containing_oneof = _STREAMINGRECOGNIZEREQUEST.oneofs_by_name['streaming_request']
_STREAMINGRECOGNITIONCONFIG.fields_by_name['config'].message_type = _RECOGNITIONCONFIG
_RECOGNITIONCONFIG.fields_by_name['encoding'].enum_type = _RECOGNITIONCONFIG_AUDIOENCODING
_RECOGNITIONCONFIG.fields_by_name['speech_contexts'].message_type = _SPEECHCONTEXT
_RECOGNITIONCONFIG.fields_by_name['model_param'].message_type = _MODELPARAM
_RECOGNITIONCONFIG_AUDIOENCODING.containing_type = _RECOGNITIONCONFIG
_RECOGNITIONAUDIO.oneofs_by_name['audio_source'].fields.append(
  _RECOGNITIONAUDIO.fields_by_name['content'])
_RECOGNITIONAUDIO.fields_by_name['content'].containing_oneof = _RECOGNITIONAUDIO.oneofs_by_name['audio_source']
_RECOGNITIONAUDIO.oneofs_by_name['audio_source'].fields.append(
  _RECOGNITIONAUDIO.fields_by_name['uri'])
_RECOGNITIONAUDIO.fields_by_name['uri'].containing_oneof = _RECOGNITIONAUDIO.oneofs_by_name['audio_source']
_RECOGNIZERESPONSE.fields_by_name['results'].message_type = _SPEECHRECOGNITIONRESULT
_STREAMINGRECOGNIZERESPONSE.fields_by_name['results'].message_type = _STREAMINGRECOGNITIONRESULT
_STREAMINGRECOGNIZERESPONSE.fields_by_name['speech_event_type'].enum_type = _STREAMINGRECOGNIZERESPONSE_SPEECHEVENTTYPE
_STREAMINGRECOGNIZERESPONSE_SPEECHEVENTTYPE.containing_type = _STREAMINGRECOGNIZERESPONSE
_STREAMINGRECOGNITIONRESULT.fields_by_name['alternatives'].message_type = _SPEECHRECOGNITIONALTERNATIVE
_SPEECHRECOGNITIONRESULT.fields_by_name['alternatives'].message_type = _SPEECHRECOGNITIONALTERNATIVE
_SPEECHRECOGNITIONALTERNATIVE.fields_by_name['words'].message_type = _WORDINFO
_WORDINFO.fields_by_name['start_time'].message_type = _DURATION
_WORDINFO.fields_by_name['end_time'].message_type = _DURATION
DESCRIPTOR.message_types_by_name['IntentRecognizeRequest'] = _INTENTRECOGNIZEREQUEST
DESCRIPTOR.message_types_by_name['StreamingIntentRecognizeResponse'] = _STREAMINGINTENTRECOGNIZERESPONSE
DESCRIPTOR.message_types_by_name['IntentRecognizeResult'] = _INTENTRECOGNIZERESULT
DESCRIPTOR.message_types_by_name['TtsRequest'] = _TTSREQUEST
DESCRIPTOR.message_types_by_name['TtsResponse'] = _TTSRESPONSE
DESCRIPTOR.message_types_by_name['RecognizeRequest'] = _RECOGNIZEREQUEST
DESCRIPTOR.message_types_by_name['StreamingRecognizeRequest'] = _STREAMINGRECOGNIZEREQUEST
DESCRIPTOR.message_types_by_name['StreamingRecognitionConfig'] = _STREAMINGRECOGNITIONCONFIG
DESCRIPTOR.message_types_by_name['RecognitionConfig'] = _RECOGNITIONCONFIG
DESCRIPTOR.message_types_by_name['ModelParam'] = _MODELPARAM
DESCRIPTOR.message_types_by_name['SpeechContext'] = _SPEECHCONTEXT
DESCRIPTOR.message_types_by_name['RecognitionAudio'] = _RECOGNITIONAUDIO
DESCRIPTOR.message_types_by_name['RecognizeResponse'] = _RECOGNIZERESPONSE
DESCRIPTOR.message_types_by_name['StreamingRecognizeResponse'] = _STREAMINGRECOGNIZERESPONSE
DESCRIPTOR.message_types_by_name['StreamingRecognitionResult'] = _STREAMINGRECOGNITIONRESULT
DESCRIPTOR.message_types_by_name['SpeechRecognitionResult'] = _SPEECHRECOGNITIONRESULT
DESCRIPTOR.message_types_by_name['SpeechRecognitionAlternative'] = _SPEECHRECOGNITIONALTERNATIVE
DESCRIPTOR.message_types_by_name['WordInfo'] = _WORDINFO
DESCRIPTOR.message_types_by_name['Duration'] = _DURATION
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

IntentRecognizeRequest = _reflection.GeneratedProtocolMessageType('IntentRecognizeRequest', (_message.Message,), {
  'DESCRIPTOR' : _INTENTRECOGNIZEREQUEST,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.IntentRecognizeRequest)
  })
_sym_db.RegisterMessage(IntentRecognizeRequest)

StreamingIntentRecognizeResponse = _reflection.GeneratedProtocolMessageType('StreamingIntentRecognizeResponse', (_message.Message,), {
  'DESCRIPTOR' : _STREAMINGINTENTRECOGNIZERESPONSE,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.StreamingIntentRecognizeResponse)
  })
_sym_db.RegisterMessage(StreamingIntentRecognizeResponse)

IntentRecognizeResult = _reflection.GeneratedProtocolMessageType('IntentRecognizeResult', (_message.Message,), {
  'DESCRIPTOR' : _INTENTRECOGNIZERESULT,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.IntentRecognizeResult)
  })
_sym_db.RegisterMessage(IntentRecognizeResult)

TtsRequest = _reflection.GeneratedProtocolMessageType('TtsRequest', (_message.Message,), {
  'DESCRIPTOR' : _TTSREQUEST,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.TtsRequest)
  })
_sym_db.RegisterMessage(TtsRequest)

TtsResponse = _reflection.GeneratedProtocolMessageType('TtsResponse', (_message.Message,), {
  'DESCRIPTOR' : _TTSRESPONSE,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.TtsResponse)
  })
_sym_db.RegisterMessage(TtsResponse)

RecognizeRequest = _reflection.GeneratedProtocolMessageType('RecognizeRequest', (_message.Message,), {
  'DESCRIPTOR' : _RECOGNIZEREQUEST,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.RecognizeRequest)
  })
_sym_db.RegisterMessage(RecognizeRequest)

StreamingRecognizeRequest = _reflection.GeneratedProtocolMessageType('StreamingRecognizeRequest', (_message.Message,), {
  'DESCRIPTOR' : _STREAMINGRECOGNIZEREQUEST,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.StreamingRecognizeRequest)
  })
_sym_db.RegisterMessage(StreamingRecognizeRequest)

StreamingRecognitionConfig = _reflection.GeneratedProtocolMessageType('StreamingRecognitionConfig', (_message.Message,), {
  'DESCRIPTOR' : _STREAMINGRECOGNITIONCONFIG,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.StreamingRecognitionConfig)
  })
_sym_db.RegisterMessage(StreamingRecognitionConfig)

RecognitionConfig = _reflection.GeneratedProtocolMessageType('RecognitionConfig', (_message.Message,), {
  'DESCRIPTOR' : _RECOGNITIONCONFIG,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.RecognitionConfig)
  })
_sym_db.RegisterMessage(RecognitionConfig)

ModelParam = _reflection.GeneratedProtocolMessageType('ModelParam', (_message.Message,), {
  'DESCRIPTOR' : _MODELPARAM,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.ModelParam)
  })
_sym_db.RegisterMessage(ModelParam)

SpeechContext = _reflection.GeneratedProtocolMessageType('SpeechContext', (_message.Message,), {
  'DESCRIPTOR' : _SPEECHCONTEXT,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.SpeechContext)
  })
_sym_db.RegisterMessage(SpeechContext)

RecognitionAudio = _reflection.GeneratedProtocolMessageType('RecognitionAudio', (_message.Message,), {
  'DESCRIPTOR' : _RECOGNITIONAUDIO,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.RecognitionAudio)
  })
_sym_db.RegisterMessage(RecognitionAudio)

RecognizeResponse = _reflection.GeneratedProtocolMessageType('RecognizeResponse', (_message.Message,), {
  'DESCRIPTOR' : _RECOGNIZERESPONSE,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.RecognizeResponse)
  })
_sym_db.RegisterMessage(RecognizeResponse)

StreamingRecognizeResponse = _reflection.GeneratedProtocolMessageType('StreamingRecognizeResponse', (_message.Message,), {
  'DESCRIPTOR' : _STREAMINGRECOGNIZERESPONSE,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.StreamingRecognizeResponse)
  })
_sym_db.RegisterMessage(StreamingRecognizeResponse)

StreamingRecognitionResult = _reflection.GeneratedProtocolMessageType('StreamingRecognitionResult', (_message.Message,), {
  'DESCRIPTOR' : _STREAMINGRECOGNITIONRESULT,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.StreamingRecognitionResult)
  })
_sym_db.RegisterMessage(StreamingRecognitionResult)

SpeechRecognitionResult = _reflection.GeneratedProtocolMessageType('SpeechRecognitionResult', (_message.Message,), {
  'DESCRIPTOR' : _SPEECHRECOGNITIONRESULT,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.SpeechRecognitionResult)
  })
_sym_db.RegisterMessage(SpeechRecognitionResult)

SpeechRecognitionAlternative = _reflection.GeneratedProtocolMessageType('SpeechRecognitionAlternative', (_message.Message,), {
  'DESCRIPTOR' : _SPEECHRECOGNITIONALTERNATIVE,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.SpeechRecognitionAlternative)
  })
_sym_db.RegisterMessage(SpeechRecognitionAlternative)

WordInfo = _reflection.GeneratedProtocolMessageType('WordInfo', (_message.Message,), {
  'DESCRIPTOR' : _WORDINFO,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.WordInfo)
  })
_sym_db.RegisterMessage(WordInfo)

Duration = _reflection.GeneratedProtocolMessageType('Duration', (_message.Message,), {
  'DESCRIPTOR' : _DURATION,
  '__module__' : 'cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:vais.cloud.speech.v1.Duration)
  })
_sym_db.RegisterMessage(Duration)


DESCRIPTOR._options = None

_SPEECH = _descriptor.ServiceDescriptor(
  name='Speech',
  full_name='vais.cloud.speech.v1.Speech',
  file=DESCRIPTOR,
  index=0,
  serialized_options=None,
  serialized_start=2648,
  serialized_end=3411,
  methods=[
  _descriptor.MethodDescriptor(
    name='Recognize',
    full_name='vais.cloud.speech.v1.Speech.Recognize',
    index=0,
    containing_service=None,
    input_type=_RECOGNIZEREQUEST,
    output_type=_RECOGNIZERESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='StreamingIntentRecognize',
    full_name='vais.cloud.speech.v1.Speech.StreamingIntentRecognize',
    index=1,
    containing_service=None,
    input_type=_STREAMINGRECOGNIZEREQUEST,
    output_type=_STREAMINGINTENTRECOGNIZERESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='StreamingRecognize',
    full_name='vais.cloud.speech.v1.Speech.StreamingRecognize',
    index=2,
    containing_service=None,
    input_type=_STREAMINGRECOGNIZEREQUEST,
    output_type=_STREAMINGRECOGNIZERESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='Text2SpeechHmmAiHoa',
    full_name='vais.cloud.speech.v1.Speech.Text2SpeechHmmAiHoa',
    index=3,
    containing_service=None,
    input_type=_TTSREQUEST,
    output_type=_TTSRESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='Text2SpeechHmmMinhNguyet',
    full_name='vais.cloud.speech.v1.Speech.Text2SpeechHmmMinhNguyet',
    index=4,
    containing_service=None,
    input_type=_TTSREQUEST,
    output_type=_TTSRESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='Text2SpeechConcatAiHoa',
    full_name='vais.cloud.speech.v1.Speech.Text2SpeechConcatAiHoa',
    index=5,
    containing_service=None,
    input_type=_TTSREQUEST,
    output_type=_TTSRESPONSE,
    serialized_options=None,
  ),
  _descriptor.MethodDescriptor(
    name='Text2SpeechConcatMinhNguyet',
    full_name='vais.cloud.speech.v1.Speech.Text2SpeechConcatMinhNguyet',
    index=6,
    containing_service=None,
    input_type=_TTSREQUEST,
    output_type=_TTSRESPONSE,
    serialized_options=None,
  ),
])
_sym_db.RegisterServiceDescriptor(_SPEECH)

DESCRIPTOR.services_by_name['Speech'] = _SPEECH

# @@protoc_insertion_point(module_scope)
